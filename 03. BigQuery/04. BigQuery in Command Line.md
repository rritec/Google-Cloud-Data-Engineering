# BigQuery in Command Line
## Overview
1. Storing and querying massive datasets can be time consuming and expensive without the right hardware and infrastructure.
2. BigQuery is a serverless, highly scalable cloud data warehouse that solves this problem by enabling super-fast SQL queries using the processing power of Google's infrastructure.
3. Simply move your data into BigQuery and let us handle the hard work.
4. You can control access to both the project and your data based on your business needs, such as giving others the ability to view or query your data.
5. You can access BigQuery by using the [Console](https://cloud.google.com/bigquery/docs/quickstarts/query-public-dataset-console), [Web UI](https://console.cloud.google.com/bigquery?utm_source=bqui&utm_medium=link&utm_campaign=classic&project=cloud-solutions-group) or a [command-line tool](https://cloud.google.com/bigquery/docs/bq-command-line-tool) using a variety of client libraries such as Java, .NET, or Python.
6. There are also a variety of [solution providers](https://cloud.google.com/bigquery/?hl=en) that you can use to interact with BigQuery.
7. This hands-on lab shows you how to use **bq**, the python-based command line tool for BigQuery, to query public tables and load sample data into BigQuery.
8. What you'll do
    1. Query a public dataset
    2. Create a new dataset
    3. Load data into a new table
    4. Query a custom table

## Task 1. Examine a table
1. BigQuery offers a number of sample tables that you can run queries against. In this lab, you'll run queries against the shakespeare table, which contains an entry for every word in every play.
2. To examine the schema of the Shakespeare table in the samples dataset, run:

``` sql
bq show bigquery-public-data:samples.shakespeare
```

## Task 2. Run the help command

1. When you include a command name with the help commands, you get information about that specific command.
2. For example, the following call to bq help retrieves information about the query command:
``` sql
bq help query
```
3. To see a list of all of the commands bq uses, run just **bq help**.

## Task 3. Run a query

1. Now you'll run a query to see how many times the substring "raisin" appears in Shakespeare's works.
2. To run a query, run the command bq query "[SQL_STATEMENT]":
3. Run the following standard SQL query in Cloud Shell to count the number of times that the substring "raisin" appears in all of Shakespeare's works:

``` sql
bq query --use_legacy_sql=false \
'SELECT
   word,
   SUM(word_count) AS count
 FROM
   `bigquery-public-data`.samples.shakespeare
 WHERE
   word LIKE "%raisin%"
 GROUP BY
   word'
```
4. In this command: --use_legacy_sql=false makes standard SQL the default query syntax.
5. Output:


|     word      | count |
|---------------|-------|
| praising      |     8 |
| Praising      |     4 |
| raising       |     5 |
| dispraising   |     2 |
| dispraisingly |     1 |
| raisins       |     1 |
The table demonstrates that although the actual word raisin doesn't appear, the letters appear in order in several of Shakespeare's works.

Test completed task
Click Check my progress to verify your performed task. If you have successfully run a query against a public dataset, you will see an assessment score.

Assessment Completed!
Run a query (dataset: samples, table: shakespeare, substring: raisin)

Assessment Completed!
If you search for a word that isn't in Shakespeare's works, no results are returned.

Run the following search for "huzzah", returns no matches:
bq query --use_legacy_sql=false \
'SELECT
   word
 FROM
   `bigquery-public-data`.samples.shakespeare
 WHERE
   word = "huzzah"'
Copied!
Test completed task
Click Check my progress to verify your performed task. If you have successfully run a query against a public dataset, you will see an assessment score.

Assessment Completed!
Run a query (dataset: samples, table: shakespeare, substring: huzzah)

Assessment Completed!
Task 4. Create a new table
Now create your own table. Every table is stored inside a dataset. A dataset is a group of resources, such as tables and views.

Create a new dataset
Use the bq ls command to list any existing datasets in your project:
bq ls
Copied!
You will be brought back to the command line since there aren't any datasets in your project yet.

Run bq ls and the bigquery-public-data Project ID to list the datasets in that specific project, followed by a colon (:):
bq ls bigquery-public-data:
Copied!
Output:

           datasetId
 -----------------------------
  austin_311
  austin_bikeshare
  austin_crime
  austin_incidents
  austin_waste
  baseball
  bitcoin_blockchain
  bls
  census_bureau_construction
  census_bureau_international
  census_bureau_usa
  census_utility
  chicago_crime
  ...
Now create a dataset. A dataset name can be up to 1,024 characters long, and consist of A-Z, a-z, 0-9, and the underscore, but it cannot start with a number or underscore, or have spaces.

Use the bq mk command to create a new dataset named babynames in your project:
bq mk babynames
Copied!
Sample output:

Dataset 'qwiklabs-gcp-ba3466847fe3cec0:babynames' successfully created.
Test completed task
Click Check my progress to verify your performed task. If you have successfully created a BigQuery dataset named babynames, you will see an assessment score.

Assessment Completed!
Create a new dataset (name: babynames)

Assessment Completed!
Run bq ls to confirm that the dataset now appears as part of your project:
bq ls
Copied!
Sample output:

 datasetId
 -------------
 babynames
Upload the dataset
Before you can build the table, you need to add the dataset to your project. The custom data file you'll use contains approximately 7 MB of data about popular baby names, provided by the US Social Security Administration.

Run this command to add the baby names zip file to your project, using the URL for the data file:
curl -LO http://www.ssa.gov/OACT/babynames/names.zip
Copied!
List the file:
ls
Copied!
You can see the name of the file added to your project.

Now unzip the file:
unzip names.zip
Copied!
That's a pretty big list of text files! List the files again:
ls
Copied!
The bq load command creates or updates a table and loads data in a single step.

You will use the bq load command to load your source file into a new table called names2010 in the babynames dataset you just created. By default, this runs synchronously, and will take a few seconds to complete.

The bq load arguments you'll be running are:

datasetID: babynames
tableID: names2010
source: yob2010.txt
schema: name:string,gender:string,count:integer
Create your table:
bq load babynames.names2010 yob2010.txt name:string,gender:string,count:integer
Copied!
Sample output:

Waiting on job_4f0c0878f6184119abfdae05f5194e65 ... (35s) Current status: DONE
Test completed task
Click Check my progress to verify your performed task. If you have successfully loaded data into a dataset table, you will see an assessment score.

Assessment Completed! Table name(s): ["names2010"]
Load the data into a new table

Assessment Completed! Table name(s): ["names2010"]
Run bq ls and babynames to confirm that the table now appears in your dataset:
bq ls babynames
Copied!
Output:

  tableId    Type
 ----------- -------
  names2010   TABLE
Run bq show and your dataset.table to see the schema:
bq show babynames.names2010
Copied!
Output:

   Last modified         Schema         Total Rows   Total Bytes     Expiration      Time Partitioning   Clustered Fields   Labels
 ----------------- ------------------- ------------ ------------- ----------------- ------------------- ------------------ --------
  13 Aug 14:37:34   |- name: string     34073        654482        12 Oct 14:37:34
                    |- gender: string
                    |- count: integer
Note: By default, when you load data, BigQuery expects UTF-8 encoded data. If you have data that is in ISO-8859-1 (or Latin-1) encoding and are having problems with your loaded data, you can tell BigQuery to treat your data as Latin-1 explicitly, using the -E flag. Learn more about Character Encodings from the Introduction to loading data guide.
Task 5. Run queries
Now you're ready to query the data and return some interesting results.

Run the following command to return the top 5 most popular girls names:
bq query "SELECT name,count FROM babynames.names2010 WHERE gender = 'F' ORDER BY count DESC LIMIT 5"
Copied!
Output:

Waiting on job_58c0f5ca52764ef1902eba611b71c651 ... (0s) Current status: DONE
+----------+-------+
|   name   | count |
+----------+-------+
| Isabella | 22913 |
| Sophia   | 20643 |
| Emma     | 17345 |
| Olivia   | 17028 |
| Ava      | 15433 |
+----------+-------+
Run the following command to see the top 5 most unusual boys names:
bq query "SELECT name,count FROM babynames.names2010 WHERE gender = 'M' ORDER BY count ASC LIMIT 5"
Copied!
Note: The minimum count is 5 because the source data omits names with fewer than 5 occurrences.
Output:

Waiting on job_556ba2e5aad340a7b2818c3e3280b7a3 ... (1s) Current status: DONE
+----------+-------+
|   name   | count |
+----------+-------+
| Aaqib    |     5 |
| Aaidan   |     5 |
| Aadhavan |     5 |
| Aarian   |     5 |
| Aamarion |     5 |
+----------+-------+
Test completed task
Click Check my progress to verify your performed task. If you have successfully a against a custom dataset, you will see an assessment score.

Assessment Completed!
Run queries against your dataset table

Assessment Completed!
Task 6. Test your Understanding
Below are multiple choice questions to reinforce your understanding of this lab's concepts. Answer them to the best of your abilities.


You can access BigQuery using:

GLib
check
Command line tool

GStreamer
check
Web UI
check
BigQuery REST API


Which CLI tool is used to interact with BigQuery service?

gcloud
check
bq

compute

gsutil

Task 7. Clean up
Run the bq rm command to remove the babynames dataset with the -r flag to delete all tables in the dataset:
bq rm -r babynames
Copied!
Confirm the delete command by typing Y.
