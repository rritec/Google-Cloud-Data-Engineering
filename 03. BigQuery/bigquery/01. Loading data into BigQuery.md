# Overview
1. BigQuery is Google's fully managed, NoOps, low cost analytics database. With BigQuery you can query terabytes and terabytes of data without having any infrastructure to manage or needing a database administrator. BigQuery uses SQL and can take advantage of the pay-as-you-go model. BigQuery allows you to focus on analyzing data to find meaningful insights.
2. In this lab you will ingest subsets of the NYC taxi trips data into tables inside of BigQuery.

# What you'll learn
1. Loading data into BigQuery from various sources
2. Loading data into BigQuery using the CLI and Console
3. Using DDL to create tables

# Task 1. Create a new dataset to store tables

1. To create a dataset, click on the View actions icon (the three vertical dots) next to your project ID and select Create dataset.
2. Next, name your Dataset ID **nyctaxi** and leave all other options at their default values, and then click **Create dataset.**
3. You'll now see the nyctaxi dataset under your project name.

# Task 2. Ingest a new dataset from a CSV
1. In this section, you will load a local CSV into a BigQuery table.
2. Download a subset of the NYC taxi 2018 trips data locally onto your computer from this [link](https://storage.googleapis.com/cloud-training/OCBL013/nyc_tlc_yellow_trips_2018_subset_1.csv).
3. In the BigQuery Console, Select the nyctaxi dataset then click **Create Table**
4. Specify the below table options:
5. Source:
    1. Create table from: Upload
    2. Choose File: select the file you downloaded locally earlier
    3. File format: CSV
6. Destination:
    1. Table name: 2018trips Leave all other settings at default.
7. Schema:
    1. Check Auto Detect (tip: Not seeing the checkbox? Ensure the file format is CSV and not Avro)
8. Advanced Options
    1. Leave at default values
9. Click **Create Table**.
10. You should now see the 2018trips table below the nyctaxi dataset.
11. Select the 2018trips table and view details:

## Running SQL Queries

1. In the Query Editor, write a query to list the top 5 most expensive trips of the year:
``` sql
#standardSQL
SELECT
  *
FROM
  nyctaxi.2018trips
ORDER BY
  fare_amount DESC
LIMIT  5
```
# Task 3. Ingest a new dataset from Google Cloud Storage
1. Now, let's try to load another subset of the same 2018 trip data that is available on Cloud Storage. And this time, let's use the CLI tool to do it.
2. In your Cloud Shell, run the following command :
``` sh
bq load \
--source_format=CSV \
--autodetect \
--noreplace  \
nyctaxi.2018trips \
gs://cloud-training/OCBL013/nyc_tlc_yellow_trips_2018_subset_2.csv
```
3. When the load job is complete, you will get a confirmation on the screen.
4. Back on your BigQuery console, select the 2018trips table and view details. Confirm that the row count has now almost doubled.
5. You may want to run the same query like earlier to see if the top 5 most expensive trips have changed.

# Task 4. Create tables from other tables with DDL

1. The 2018trips table now has trips from throughout the year. What if you were only interested in January trips? For the purpose of this lab, we will keep it simple and focus only on pickup date and time. Let's use DDL to extract this data and store it in another table
2. In the Query Editor, run the following CREATE TABLE command :
``` sql
#standardSQL
CREATE TABLE
  nyctaxi.january_trips AS
SELECT
  *
FROM
  nyctaxi.2018trips
WHERE
  EXTRACT(Month
  FROM
    pickup_datetime)=1;
```

3. Now run the below query in your Query Editor find the longest distance traveled in the month of January:

``` sql
#standardSQL
SELECT
  *
FROM
  nyctaxi.january_trips
ORDER BY
  trip_distance DESC
LIMIT
  1
```

# Questions
# Answers
