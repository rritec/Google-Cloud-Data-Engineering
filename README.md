# Google Cloud(GCP)-Data-Engineering Course Content


------

This Repository has **Cloud Data Engineering** Training Materials developed by **Myla Ram Reddy**.

Please contact **Renuka** for **Training and Certification** @ [8374899166](https://wa.me/918374899166)(whatsapp)

------



<details>
<summary> 01. Python</summary>

<details>
<summary>Python Basic Level</summary>

1. Install Anaconda
1. understand markdown language
1. How to write Python code in normal notepad
2. How to write Python code in spyder
3. How to write Python code in Visual Studio Code
4. How to write Python code in in jupyter/ JupyterLab
5. Different Python Objects
1. int
2. float
3. complex
4. str
5. bool
6. range
6. Data Structures
1. list
2. Dict
3. Tuple
4. Set
5. Mutable Vs Immutable
7. Read items of str /list/Dict/Tuple/Set/range ..etc
1. index
2. slice
3. fancy
8. Operators
1. Comparision(>,<,>=,<=,...)
2. Logical/bool(and/or/not)
3. Numpy logical (logical_and/logical_or/logical_not)
9. Control Flows
1. input
2. if elif elif ... else
3. while loop
4. break
5. continue
6. for loop

</details>

<details>
<summary>Advanced Python</summary>

1. System_Defined_Functions
1. create functions
1. function parameter
1. manadatory parameters
1. optional parameters
1. flexiable parameters
1. key value flexiable parameters
2. LEGB_scope_of_objects_of_functions
3. Methods
4. Modules
5. User_defined_packages
6. system_defined_packages
7. Iterables & Iterators
8. Lambda_Functions
9. Syntax Errors and Exceptions
10. List comprehensions
11. OOPs_Introduction_Classes_Objects_Attributes_Methods
12. OOPs_Inheritance_and_MRO
13. OOPs_Encapsulation
14. OOPs_Polymorphism



</details>
</details>

<details>
<summary>02. BigData</summary>


### **BigData Introduction**

- What is BigData
- BigData properties
- When to choose bigdata

### **BigData VM Installation**

- Oracle Virtual box installation
- Cloudera VM installation
- winscp Installation
- Putty Installation

### **Linux commands**

- Working with folders
- create folder
- remove folder with files
- remove folder without files
- understanding VI editor
- working with Files
- create a file
- copy file
- move file
- remove file
- cat command
- understanding permissions
- grep command
- find command
- ... etc

### **HDFS**

- mkdir command
- put command
- get command
- CopyFromLocal command
- CopyToLocal command
- rm Command
- merge command
- ... etc

### **Hive**

- Hive Metastore
- Hive Managed Tables
- Hive External Tables
- Hive Operations
- Hadoop File Formats and its Types
- Different ways to connecting hive
- Partitioning
- Bucketing

### **Sqoop**

- Sqoop Introduction
- sqoop list-tables
- Sqoop Eval
- Sqoop Import
- Sqoop Export
- Import All Tables
- Import table from mysql to hive

### **Pyspark**

- Spark Introduction
- Spark Architecture
- Spark Environment Setup (optional)
- Spark RDD with Python
- Spark RDD with Scala
- Spark DF
- Spark SQL
- Spark Structured Streaming

</details>



<details>
<summary> 03. GCP-Data-Engineering </summary>

## 03. GCP-Data-Engineering
### Fundamentals of GCP-Data-Engineering
1. What is Data Engineering
2. Data Engineer Roles & Responsibilities
3. Types of Data
4. Steaming Vs Batch Data

### Cloud Storage

1. Introduction of Cloud Storage
2. Standard Storage
3. Nearline Storage
4. Coldline Storage
5. Archive Storage
6. Create Bucket
7. Upload content to Bucket
8. Understanding renaming of files
9. Download, Share and Manage Objects

### Cloud SQL

1. What is Cloud SQL
2. Create Database of your intrest MySQL, SQL Server, PostgreSQL
3. Write different Queries.

### BigQuery

1. Introduction about BigQuery Studio
2. Create Dataset
3. Create Table
4. Load data from CSV file to BigQuery
5. Load data from JSON file to BigQuery
6. Analyse data with Queries
7. Creating and using tables
8. Introduction to partitioned tables
9. Introduction to BigQuery ML
10. Predefined roles and permissions
11. Introduction to loading data
12. Loading CSV data from Cloud Storage
13. Exporting table data
14. Create machine learning models in BigQuery ML
15. Querying external data sources

### DataFlow

1. Create a Dataflow pipeline using Python
2. Create a streaming pipeline using a Dataflow template
3. Build and run a Flex Template
4. Deploy Dataflow pipelines
5. Develop with notebooks
6. Troubleshooting and debugging

### DataProc

1. Overview of Dataproc Workflow Templates
2. Dataproc on GKE Quickstart
3. Configure Dataproc Hub
4. Create a Dataproc Custom Image
5. Write a MapReduce job with the BigQuery connector
6. Use the Cloud Storage connector with Apache Spar

### Cloud Data Fusion

1. Create a data pipeline by using Cloud Data Fusion
2. Creating a Cloud Data Fusion instance
3. Creating a private instance
4. Using JDBC drivers with Cloud Data Fusion
5. Access control
6. Enabling and disabling Cloud Data Fusion
7. Granting service account user permission
8. Viewing pipeline logs in Cloud Logging
9. Using VPC Service Controls with Cloud Data Fusion

### Composer(Airflow)

1. Run an Apache Airflow DAG in Cloud Composer 1
2. Features
3. Creating environments
4. Writing DAGs (workflows)
5. Triggering DAGs (workflows)
6. Monitoring environments
7. Setting Environment Variables

### BigTable
1. Create an instance and write data with the cbt CLI
2. Schema design best practices
3. Create and manage tables
4. Create and manage backups
5. Integrations with 

</details>
